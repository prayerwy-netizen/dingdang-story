import React, { useEffect, useRef, useState, useImperativeHandle, forwardRef } from 'react';
import { speakWithMiniMax, stopSpeaking } from '../services/geminiService';

interface AudioPlayerProps {
  audioBuffer: AudioBuffer | null;
  text?: string; // æ–‡æœ¬ï¼Œç”¨äº MiniMax è¯­éŸ³åˆæˆ
  preloadedAudio?: ArrayBuffer | null; // é¢„åŠ è½½çš„éŸ³é¢‘æ•°æ®
  autoPlay?: boolean;
  onEnded?: () => void;
}

export interface AudioPlayerHandle {
  play: () => void;
  stop: () => void;
}

// æ£€æµ‹æ˜¯å¦æ˜¯ç§»åŠ¨è®¾å¤‡ï¼ˆiOS/Androidï¼‰
const isMobileDevice = (): boolean => {
  return /iPhone|iPad|iPod|Android/i.test(navigator.userAgent);
};

// å…¨å±€æ ‡è®°ï¼šç”¨æˆ·æ˜¯å¦å·²ç»äº¤äº’è¿‡ï¼ˆæ•´ä¸ªä¼šè¯ä¸­åªéœ€è¦ä¸€æ¬¡ï¼‰
let globalHasUserInteracted = false;

// è§£é”éŸ³é¢‘æ’­æ”¾ï¼ˆiOS éœ€è¦åœ¨ç”¨æˆ·äº¤äº’æ—¶è§¦å‘ï¼‰
const unlockAudio = () => {
  if (globalHasUserInteracted) return;
  globalHasUserInteracted = true;

  // åˆ›å»ºå¹¶æ’­æ”¾ä¸€ä¸ªé™éŸ³éŸ³é¢‘æ¥è§£é” AudioContext
  try {
    const AudioContext = window.AudioContext || (window as unknown as { webkitAudioContext: typeof window.AudioContext }).webkitAudioContext;
    if (AudioContext) {
      const ctx = new AudioContext();
      const buffer = ctx.createBuffer(1, 1, 22050);
      const source = ctx.createBufferSource();
      source.buffer = buffer;
      source.connect(ctx.destination);
      source.start(0);
      ctx.resume();
    }
  } catch (e) {
    console.log('Audio unlock failed:', e);
  }
};

const AudioPlayer = forwardRef<AudioPlayerHandle, AudioPlayerProps>(({ audioBuffer, text, preloadedAudio, autoPlay, onEnded }, ref) => {
  const [isPlaying, setIsPlaying] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [needUserInteraction, setNeedUserInteraction] = useState(false);
  const cachedAudioRef = useRef<ArrayBuffer | null>(null);
  const audioElementRef = useRef<HTMLAudioElement | null>(null);

  // å¦‚æœæœ‰é¢„åŠ è½½çš„éŸ³é¢‘ï¼Œç›´æ¥ä½¿ç”¨
  useEffect(() => {
    if (preloadedAudio) {
      cachedAudioRef.current = preloadedAudio;
    }
  }, [preloadedAudio]);

  useEffect(() => {
    return () => {
      stopSpeaking();
      if (audioElementRef.current) {
        audioElementRef.current.pause();
        audioElementRef.current = null;
      }
    };
  }, []);

  // å½“ text å˜åŒ–æ—¶ï¼Œæ¸…é™¤ç¼“å­˜ï¼Œé‡ç½®çŠ¶æ€
  useEffect(() => {
    cachedAudioRef.current = null;
    setNeedUserInteraction(false);
  }, [text]);

  useEffect(() => {
    if (autoPlay && text) {
      // åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šï¼Œå¦‚æœè¿˜æ²¡æœ‰ç”¨æˆ·äº¤äº’è¿‡ï¼Œæ˜¾ç¤ºç‚¹å‡»æŒ‰é’®
      if (isMobileDevice() && !globalHasUserInteracted) {
        setNeedUserInteraction(true);
      } else {
        const timer = setTimeout(() => playAudio(), 100);
        return () => clearTimeout(timer);
      }
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [text]);

  // æ’­æ”¾ç¼“å­˜çš„éŸ³é¢‘
  const playCachedAudio = (audioData: ArrayBuffer) => {
    const blob = new Blob([audioData], { type: 'audio/mp3' });
    const url = URL.createObjectURL(blob);
    const audio = new Audio(url);
    audioElementRef.current = audio;

    audio.onended = () => {
      URL.revokeObjectURL(url);
      setIsPlaying(false);
      onEnded?.();
    };

    audio.onerror = () => {
      URL.revokeObjectURL(url);
      setIsPlaying(false);
      onEnded?.();
    };

    // ç§»åŠ¨ç«¯éœ€è¦å¤„ç† play() è¿”å›çš„ Promise
    const playPromise = audio.play();
    if (playPromise !== undefined) {
      playPromise
        .then(() => {
          // æ’­æ”¾æˆåŠŸ
        })
        .catch(() => {
          URL.revokeObjectURL(url);
          setIsPlaying(false);
          onEnded?.();
        });
    }
  };

  const playAudio = async () => {
    if (!text) return;

    // æ ‡è®°ç”¨æˆ·å·²ç»äº¤äº’è¿‡ï¼Œè§£é”éŸ³é¢‘æ’­æ”¾
    unlockAudio();
    setNeedUserInteraction(false);

    stopSpeaking();
    if (audioElementRef.current) {
      audioElementRef.current.pause();
    }

    // å¦‚æœæœ‰ç¼“å­˜ï¼Œç›´æ¥æ’­æ”¾
    if (cachedAudioRef.current) {
      setIsPlaying(true);
      playCachedAudio(cachedAudioRef.current);
      return;
    }

    setIsLoading(true);
    setIsPlaying(true);

    try {
      await speakWithMiniMax(text, () => {
        setIsPlaying(false);
        setIsLoading(false);
        onEnded?.();
      }, (audioData) => {
        // ç¼“å­˜éŸ³é¢‘æ•°æ®
        cachedAudioRef.current = audioData;
      });
    } catch (e) {
      console.error('Audio playback error:', e);
    }

    setIsLoading(false);
  };

  const stopAudio = () => {
    stopSpeaking();
    if (audioElementRef.current) {
      audioElementRef.current.pause();
      audioElementRef.current = null;
    }
    setIsPlaying(false);
    setIsLoading(false);
  };

  useImperativeHandle(ref, () => ({
    play: playAudio,
    stop: stopAudio
  }));

  if (!text) return null;

  // iOS/ç§»åŠ¨è®¾å¤‡é¦–æ¬¡éœ€è¦ç”¨æˆ·ç‚¹å‡»æ‰èƒ½æ’­æ”¾éŸ³é¢‘
  if (needUserInteraction) {
    return (
      <div className="flex justify-center mt-4">
        <button
          onClick={playAudio}
          className="px-6 py-3 rounded-full flex items-center gap-2 bg-accent-orange text-white font-semibold shadow-lg animate-pulse cursor-pointer"
        >
          <span className="text-xl">ğŸ”Š</span> ç‚¹å‡»å¼€å§‹æ’­æ”¾
        </button>
      </div>
    );
  }

  return (
    <div className="flex flex-col items-center mt-4">
      <button
        onClick={isPlaying ? stopAudio : playAudio}
        disabled={isLoading}
        className={`px-4 py-2 rounded-full flex items-center gap-2 transition-colors cursor-pointer ${
          isPlaying ? 'bg-orange-100 text-orange-600' : 'bg-primary-500 text-white'
        } ${isLoading ? 'opacity-70' : ''}`}
      >
        {isLoading ? (
          <>
            <span className="animate-spin">â³</span> åŠ è½½ä¸­...
          </>
        ) : isPlaying ? (
          <>
            <span className="animate-pulse">ğŸ”Š</span> æ’­æ”¾ä¸­...
          </>
        ) : (
          <>
            <span>â–¶ï¸</span> å†å¬ä¸€é
          </>
        )}
      </button>
    </div>
  );
});

export default AudioPlayer;
